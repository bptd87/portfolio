# robots.txt for Scenic Design & Software
# 
# This file tells search engines which pages to crawl and which to ignore.
# Place this file at /public/robots.txt after updating the sitemap URL.

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow admin or utility pages (add if needed)
# Disallow: /admin/
# Disallow: /api/

# Sitemap location
# TODO: Update this URL with your actual domain
Sitemap: https://yoursite.com/sitemap.xml

# Crawl-delay (optional, helps prevent server overload)
# Crawl-delay: 1

# Block specific bots (if needed)
# User-agent: BadBot
# Disallow: /
